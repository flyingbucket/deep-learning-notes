
## 1. 原始二分类 SVM（Hinge Loss）
- 输入：logit 分数  
  $s = w^\top x + b$
- 标签：$y \in \{-1, +1\}$
- 损失函数：  
  $L = \max(0, 1 - y \cdot s)$

说明：
- 分类正确且离边界大于 1，损失为 0  
- 分类正确但靠近边界，损失 > 0  
- 分类错误，损失很大  

## 2. 深度学习语境下的多分类 SVM（Multi-class Hinge Loss）
- 模型输出：logits  
  $s = (s_1, s_2, \dots, s_K)$
- 真实类别：$y \in \{1,2,\dots,K\}$
- 损失函数：  
  $L = \sum_{j \neq y} \max(0, s_j - s_y + \Delta), \quad \Delta = 1$

说明：
- 要求正确类别得分 $s_y$ 比错误类别得分至少大一个 margin $\Delta$  
- 不依赖 softmax，不需要概率解释  
